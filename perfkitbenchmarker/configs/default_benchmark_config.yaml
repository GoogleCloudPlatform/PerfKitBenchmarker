# PKB benchmark configs that point to a benchmark module via 'name: <BENCHMARK_NAME>'.
# This is meant to provide commonly used configs that can not be expressed through
# flag defaults or default benchmark configs.
netperf_tcp_rr:
  name: netperf
  flags:
    netperf_benchmarks: TCP_RR

netperf_tcp_stream:
  name: netperf
  flags:
    netperf_benchmarks: TCP_STREAM
    netperf_num_streams: 1,8,16,200

mysql_tpcc:
  name: hammerdbcli
  flags:
    db_engine: mysql
    db_engine_version: '8.0'
    hammerdbcli_optimized_server_configuration: restorable
    hammerdbcli_tpcc_all_warehouse: True
    hammerdbcli_tpcc_time_profile: True
    use_managed_db: False
    db_high_availability: False
    innodb_buffer_pool_ratio: 0.8
    timeout_minutes: 360
    azure_provisioned_iops: 40000
    azure_provisioned_throughput: 1200
  relational_db:
    engine: mysql
    vm_groups:
      clients:
        disk_spec:
          GCP:
            disk_size: 200
            disk_type: pd-ssd
          AWS:
            disk_size: 200
            disk_type: gp2
          Azure:
            disk_size: 200
            disk_type: Premium_LRS
      servers:
        vm_spec:
          # TODO(andytzhu) - Add AWS/Azure
          GCP:
            boot_disk_size: 200
            boot_disk_type: pd-ssd
        disk_spec:
          GCP:
            disk_size: 2000
            disk_type: pd-ssd
          # These aim to match a 2 TB PD-SSD in performance and price. AWS can get better performance.
          AWS:
            disk_size: 500
            disk_type: gp3
            provisioned_iops: 10000
            provisioned_throughput: 300
            num_striped_disks: 4
          # copybara:strip_begin(internal)
          # TODO(user) - Add Azure iops/throughput/striping.
          # copybara:strip_end
          # Azure provisioned IOPS/Throughput and striping must be configured via run-time flags.
          Azure: # Premiumv2 disks matching 4TB pd-ssd
            disk_size: 2000
            disk_type: PremiumV2_LRS

postgres_tpcc:
  name: hammerdbcli
  flags:
    db_engine: postgres
    db_engine_version: '13'
    hammerdbcli_version: '4.3'
    hammerdbcli_tpcc_time_profile: True
    hammerdbcli_tpcc_log_transactions: True
    hammerdbcli_tpcc_duration: 30
    hammerdbcli_build_timeout: 19000
    use_managed_db: False
    db_high_availability: False
    postgres_shared_buffer_ratio: 0.25
    metadata: shared_buffer_ratio:0.25
    timeout_minutes: 360
    azure_provisioned_iops: 64000
    azure_provisioned_throughput: 1200
  relational_db:
    engine: postgres
    vm_groups:
      clients:
        disk_spec:
          GCP:
            disk_size: 200
          AWS:
            disk_size: 200
          Azure:
            disk_size: 200
      servers:
        vm_spec:
          # TODO(andytzhu) - Add AWS/Azure
          GCP:
            boot_disk_size: 200
            boot_disk_type: pd-ssd
        disk_spec:
          GCP:
            disk_size: 4000
            disk_type: pd-ssd
          # These aim to match a 4 TB PD-SSD in performance and price. AWS can get better performance.
          AWS:
            disk_size: 1000
            disk_type: gp3
            provisioned_iops: 16000
            provisioned_throughput: 300
            num_striped_disks: 4
          # TODO(andytzhu) - Add Azure iops/throughput/striping.
          Azure: # Premiumv2 disks matching 4TB pd-ssd
            disk_size: 2000
            disk_type: PremiumV2_LRS

hpcc_stream:
  name: hpcc
  flags:
    enable_transparent_hugepages: True
    hpcc_benchmarks: StarSTREAM
    hpcc_math_library: openblas
    hpcc_numa_binding: True
    num_vms: 1

# TODO: memtier_key_maximum, memtier_load_key_maximum
redis_memtier_full_house_loaded:
  name: redis_memtier
  flags:
    memtier_clients: 8
    memtier_ratio: 1:9
    memtier_run_duration: 800
    memtier_threads: 4
    redis_eviction_policy: allkeys-lru
    redis_server_io_threads: 0
    redis_server_version: 5.0.5
    redis_total_num_processes: 0
    metadata: load_key_ratio:0.9
    metadata: max_key_ratio:1.1
    metadata: scenario:full_house_loaded

# TODO: redis_server_io_threads
redis_memtier_single_process:
  name: redis_memtier
  flags:
    memtier_clients: 100
    memtier_key_maximum: 10000000
    memtier_load_key_maximum: 1
    memtier_ratio: 1:10
    memtier_run_duration: 1800
    memtier_threads: 16
    redis_server_version: 6.2.1
    redis_total_num_processes: 1
    metadata: load_key_ratio:0
    metadata: max_key_ratio:N/A
    metadata: scenario:single_process

sparksql_tpcds_1t:
  name: dpb_sparksql_benchmark
  flags:
    create_and_boot_post_task_delay: 2
    dpb_sparksql_copy_to_hdfs: True
    dpb_sparksql_create_hive_tables: False
    dpb_sparksql_data_compression: snappy
    dpb_sparksql_data_format: parquet
    dpb_sparksql_order: 1,2,3,4,5,6,7,8,9,10,11,12,13,14a,14b,15,16,17,18,19,20,21,22,23a,23b,24a,24b,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39a,39b,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99
    dpb_sparksql_query: tpcds_2_4
    metadata: scale:1T,data_source:HDFS
    openjdk_version: 11
  dpb_service:
    service_type: unmanaged_spark_cluster
    worker_count: 8
    worker_group:
      vm_spec:
        GCP:
          num_local_ssds: 0
      disk_spec:
        GCP:
          disk_size: 500
          disk_type: pd-ssd
        AWS:
          disk_size: 500
          disk_type: gp3
          provisioned_iops: 5000
          provisioned_throughput: 480
